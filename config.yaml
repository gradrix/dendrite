# AI Agent Configuration

# Ollama settings
ollama:
  base_url: "http://ollama:11434"  # Using Docker network to reach Ollama container
  
  # Model selection strategy:
  # - "auto": Automatically select best model based on available RAM/VRAM
  # - "mistral-small3.2:24b": Specific model (24B, excellent reasoning, better counting)
  # - "qwen2.5:32b": Specific model (32B, high quality, good counting)
  # - "llama3.1:8b": Specific model (8B, balanced, Raspberry Pi capable)
  # - "qwen2.5:3b": Specific model (3B, fast, minimal resources)
  model: "auto"  # Will auto-detect best model on startup
  
  # Fallback if auto-detection fails
  fallback_model: "llama3.1:8b"
  
  timeout: 600  # 5 minutes for generation and analysis
  max_retries: 3
  temperature: 0.7
  
  # Force Python tools for counting tasks (recommended for all models)
  # Even large models can miscount - Python is 100% reliable
  force_python_counting: true
  
# Agent settings
agent:
  name: "Strava Monitor Agent"
  check_interval_minutes: 60  # How often to run (60 = hourly)
  enabled: true
  dry_run: false  # Set to true to simulate actions without executing
  
# Logging
logging:
  level: "INFO"  # DEBUG, INFO, WARNING, ERROR
  log_to_file: true
  log_dir: "logs"
  max_log_size_mb: 100
  backup_count: 5
  
# State management
state:
  database: "state/agent_state.db"
  retention_days: 90  # How long to keep history
  
# Safety settings
safety:
  require_approval_for_writes: false  # Set true for human-in-the-loop
  max_actions_per_run: 10
  action_cooldown_seconds: 5  # Delay between actions
  
# Strava settings
strava:
  cookies_file: ".strava_cookies"  # Will be gitignored
  rate_limit_per_minute: 100
  timeout: 30
