# Quick Reference: Model Management & Smart Counting

## ðŸš€ Quick Start

```bash
# 1. Auto-detect best model for your system
./manage-models.sh auto

# 2. Run agent with counting task
./start-agent.sh --once --instruction test_count_runs --text
```

## ðŸ“Š Model Management Commands

```bash
./manage-models.sh auto              # Auto-detect & setup
./manage-models.sh list              # Show downloaded models
./manage-models.sh use <model>       # Switch to specific model
./manage-models.sh recommend         # See recommendation
./manage-models.sh info              # Full system status
```

## âš™ï¸ Configuration

### Auto-Detection (Recommended)
```yaml
# config.yaml
ollama:
  model: "auto"  # Automatically selects best model
  force_python_counting: true  # Use Python for accurate counting
```

### Manual Selection
```yaml
ollama:
  model: "mistral-small3.2:24b"  # Specific model
```

### VRAM Override
```bash
# .env
VRAM_GB=32  # Override auto-detection
```

## ðŸŽ¯ Model Recommendations

| Your System | Recommended Model |
|-------------|-------------------|
| 4-8GB RAM | `qwen2.5:3b` |
| 8-16GB RAM | `llama3.1:8b` |
| 16-32GB RAM | `qwen2.5:14b` |
| 32GB+ RAM + 16GB+ GPU | `mistral-small3.2:24b` |
| 64GB+ RAM + 24GB+ GPU | `qwen2.5:32b` |

## ðŸ”§ What Was Fixed

### Problem 1: Counting Inaccuracy
**Before**: AI counted 2 runs when there were actually 8
**After**: Strategy advisor forces Python execution â†’ 100% accurate

### Problem 2: Context Overflow  
**Before**: 57 activities Ã— ~2KB polylines = ~114KB context
**After**: 57 activities Ã— 6 fields = ~4KB (27x smaller)

### Problem 3: Manual Model Selection
**Before**: Edit config.yaml, check resources manually, download model
**After**: `./manage-models.sh auto` does everything

## ðŸ’¡ Key Features

âœ… **Automatic resource detection** (RAM/VRAM)
âœ… **Compact context storage** (removes polylines)
âœ… **Strategy advisor** (guides tool selection)
âœ… **Python execution for counting** (100% reliable)
âœ… **Unified model management** (one script, all operations)
âœ… **Smart tool selection** (executeDataAnalysis for counting)

## ðŸ“ Example: Counting Activities

```bash
# Ask: "How many running activities in September 2024?"

# Agent will:
1. Detect counting task
2. Recommend Python tool via strategy advisor
3. Convert date to timestamps
4. Fetch activities (compact format, 6 fields only)
5. Use executeDataAnalysis with Python:
   result = len([x for x in data['neuron_0_2']['activities'] 
                 if 'Run' in x.get('sport_type', '')])
6. Return accurate count: 8 activities âœ…
```

## ðŸ” Troubleshooting

### Model not found
```bash
# Download it
./manage-models.sh download mistral-small3.2:24b
```

### VRAM not detected
```bash
# Add to .env
echo "VRAM_GB=32" >> .env
```

### Wrong model selected
```bash
# Override with specific model
./manage-models.sh use llama3.1:8b
```

### AI still miscounting
```bash
# Ensure force_python_counting is enabled in config.yaml
ollama:
  force_python_counting: true
```

## ðŸ“š More Info

- Full details: `MODEL_MANAGEMENT_SUMMARY.md`
- Model profiles: `agent/model_config.py`
- Resource detection: `agent/resource_detector.py`
- Strategy advisor: `agent/neuron_agent.py` (line 690+)

## ðŸŽ¨ System Architecture

```
User Request
    â†“
Strategy Advisor (detects counting task)
    â†“
Decompose Goal â†’ Neurons
    â†“
Neuron 1: Convert dates (getDateRangeTimestamps)
    â†“
Neuron 2: Fetch activities (getMyActivities)
    â†“  â†’ Compact Storage (6 fields, no polylines)
    â†“
Neuron 3: Count with Python (executeDataAnalysis)
    â†“  â†’ result = len([x for x in data['activities'] if 'Run' in x['sport_type']])
    â†“
Format & Return â†’ 100% accurate count âœ…
```

## ðŸŒŸ Why This Approach?

1. **Small models (3B-8B)**: Cannot count reliably â†’ Use Python
2. **Large models (32B+)**: Reasoning can cause errors â†’ Use Python  
3. **Python execution**: Simple, fast, 100% reliable
4. **Compact context**: 27x smaller â†’ Works on Raspberry Pi
5. **Auto-detection**: Zero configuration for end users

**Result**: Same agent code works on Raspberry Pi AND high-end workstations! ðŸš€
