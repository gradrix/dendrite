# Ollama Container Configuration

# Container settings
OLLAMA_CONTAINER_NAME=ollama
OLLAMA_IMAGE=ollama/ollama:latest
OLLAMA_PORT=11434
OLLAMA_HOST=0.0.0.0

# Model configuration
# Options: llama3.1:8b, llama3.2:3b, mistral:7b-instruct-v0.3, gemma2:9b
DEFAULT_MODEL=llama3.1:8b

# Network settings
DOCKER_NETWORK=ollama-network

# Resource limits (optional)
# OLLAMA_MEMORY_LIMIT=8g
# OLLAMA_CPU_LIMIT=4

# GPU support (set to true if you have NVIDIA GPU)
USE_GPU=false

# API settings
API_TIMEOUT=300
MAX_RETRIES=30
RETRY_INTERVAL=10
