# Ollama Container Configuration

# Container settings
OLLAMA_CONTAINER_NAME=ollama
OLLAMA_IMAGE=ollama/ollama:latest
OLLAMA_PORT=11434
OLLAMA_HOST=0.0.0.0

# Model configuration
# Options: llama3.1:8b, llama3.2:3b, mistral:7b-instruct-v0.3, gemma2:9b
DEFAULT_MODEL=llama3.1:8b

# Network settings
DOCKER_NETWORK=ollama-network

# Resource limits (optional)
# OLLAMA_MEMORY_LIMIT=8g
# OLLAMA_CPU_LIMIT=4

# GPU mode: true|false|auto
# - auto (default): use GPU if available and Docker is configured; else fall back to CPU
# - true: force GPU (requires NVIDIA Container Toolkit)
# - false: force CPU-only
USE_GPU=auto

# API settings
API_TIMEOUT=300
MAX_RETRIES=30
RETRY_INTERVAL=10

# ========================================
# AI Agent Settings
# ========================================

# Strava API credentials (if using OAuth in future)
STRAVA_CLIENT_ID=your_client_id_here
STRAVA_CLIENT_SECRET=your_client_secret_here
STRAVA_REFRESH_TOKEN=your_refresh_token_here

# Or use session cookies (simpler)
# Put your Strava cookies in .strava_cookies file

# Optional: Notification settings
NOTIFICATION_WEBHOOK_URL=
NOTIFICATION_EMAIL=

# Optional: Override config.yaml settings
# AGENT_DRY_RUN=true
# AGENT_CHECK_INTERVAL=30
